{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "28831321-1612-43ac-bf24-501c787afc53",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "T_VwAlry0dAc",
        "outputId": "b1557396-cab6-454d-b98a-d0e51982a733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.12/dist-packages (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "330cc775-e42b-462b-8d61-71e4400cca71",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "tw0PiH0U0dAe",
        "outputId": "e5bc7dc2-dd3c-4448-f8a0-a79f6269b527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c46d339bd40>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a649431f4830:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>MySpark_App</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import pyspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"MySpark_App\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c3218690-adb8-4c61-95e0-b1151f1098b6",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "v2w9Qxqr0dAe"
      },
      "outputs": [],
      "source": [
        "# Read raw csv file from GitHub by converting the following steps:\n",
        "# 1. Point the URL to the CSV file in raw format\n",
        "# 2. Read the CSV directly into a pandas DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/RajashekarAllala/Python_For_Data_Engineering/refs/heads/main/Data_Sets/employee_data.csv\"\n",
        "\n",
        "# 2. Read the CSV directly into a pandas DataFrame\n",
        "get_csv = pd.read_csv(url)\n",
        "\n",
        "# 3. Convert the pandas DataFrame to a Spark DataFrame\n",
        "df_csv = spark.createDataFrame(get_csv)\n",
        "\n",
        "# 4. Show the first few rows to verify\n",
        "display(df_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d78d87f2-2db5-45c9-b966-e4d3d7ea8ffb",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "8CaYAmQQ0dAf"
      },
      "outputs": [],
      "source": [
        "# Read data from a table available in catalog\n",
        "df_table = spark.read.table(\"data_sets.organization.employee_data\")\n",
        "df_table.show(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3dfb6151-7c99-4734-9edd-a5f0357f4838",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "_gjUaKgT0dAf"
      },
      "outputs": [],
      "source": [
        "# Drop tax_file_no as it contains NULL data\n",
        "df_emp = df_table.drop(\"tax_file_no\")\n",
        "df_emp.show(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "710f130f-c738-4309-ac2b-81e21b828086",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "KgsyrUF-0dAf"
      },
      "outputs": [],
      "source": [
        "# Check schema\n",
        "print(\"Schema of df_emp\")\n",
        "df_emp.printSchema()\n",
        "\n",
        "# Check data types\n",
        "print(\"Data types of df_emp\")\n",
        "df_emp.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d72bea08-718a-4c6e-a021-b73577cbf7c2",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "MwtfjFLl0dAf"
      },
      "outputs": [],
      "source": [
        "# df_emp: Change data types of number to int, and annual_salary to float.\n",
        "# Add all in one statement to optimize performance.\n",
        "df_emp = df_emp.withColumn(\"number\", F.col(\"number\").cast(T.IntegerType())) \\\n",
        "               .withColumn(\"annual_salary\", F.col(\"annual_salary\").cast(T.FloatType()))\n",
        "df_emp.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "270a5bb9-d6bd-42b7-9ec7-069f008865b8",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "SG-EpRXO0dAg"
      },
      "outputs": [],
      "source": [
        "df_emp.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "45c6a636-150a-4b49-be0c-02a65c9d80a0",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "uH10rTU60dAg"
      },
      "outputs": [],
      "source": [
        "# Check if there are any null values in gender, employment_status, annual_salary only\n",
        "df_emp.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_emp.columns]).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1c1f0ca0-a907-455b-8bfe-f74a3d67ce78",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "GhGYNXzk0dAg"
      },
      "outputs": [],
      "source": [
        "# Handle null values in gender, employment_status, annual_salary only\n",
        "# df_emp: Replace null values in gender with 'Unknown', employment_status with 'Unknown', annual_salary with 0.0\n",
        "df_emp = df_emp.fillna({'gender': 'Unknown', 'employment_status': 'Unknown', 'annual_salary': 0.0})\n",
        "df_emp.show()\n",
        "df_emp.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_emp.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2afaeb3b-c7e6-4a7b-9bbf-c69cca01da60",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "DfzpzXvE0dAg"
      },
      "outputs": [],
      "source": [
        "# Handle null values in birth_date\n",
        "# df_emp: Replace null values in birth_date with '1900-01-01'\n",
        "df_emp = df_emp.fillna({'birth_date': '1900-01-01'})\n",
        "df_emp.show()\n",
        "df_emp.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_emp.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ee38b793-0c0e-4095-be22-5175b7e3e71f",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "pNSFqw1y0dAg"
      },
      "outputs": [],
      "source": [
        "# Decide to drop or fill the values with NULL in first and last names\n",
        "# df_emp: Drop rows with NULL values in first and last names\n",
        "df_emp = df_emp.dropna(subset=['first_name', 'last_name'])\n",
        "df_emp.show()\n",
        "df_emp.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_emp.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f65c3774-46fd-446f-b003-d039c00bdac6",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "AhM_OSqR0dAg"
      },
      "outputs": [],
      "source": [
        "# Find Average, Max, and Min Salary using select\n",
        "df_emp.select(F.avg('annual_salary'), F.max('annual_salary'), F.min('annual_salary')).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ad0a23fc-890d-4d11-9174-21728ae8b0d4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "sfKFMdsS0dAg"
      },
      "outputs": [],
      "source": [
        "# Using groupBy employment_status find avg, max, and min\n",
        "df_emp.groupBy('employment_status').agg(F.avg('annual_salary'), F.max('annual_salary'), F.min('annual_salary')).orderBy(\"employment_status\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "25062b5b-0b0e-470d-bab4-b77a52253641",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "34BocE3i0dAg"
      },
      "outputs": [],
      "source": [
        "# Find number of employees in each employment_status\n",
        "df_emp.groupBy('employment_status').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a98ed32d-55d6-4ce1-b12c-17e409151ecc",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "_MyV_x6K0dAg"
      },
      "outputs": [],
      "source": [
        "# Find employees count based on gender\n",
        "df_emp.groupBy('gender').count().orderBy('gender').show()\n",
        "\n",
        "df_emp.groupBy(\"gender\", \"employment_status\").count().orderBy('gender').show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": {
        "base_environment": "",
        "environment_version": "3"
      },
      "inputWidgetPreferences": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "01-PySpark-Basics",
      "widgets": {}
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}